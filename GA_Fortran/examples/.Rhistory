prior=toy_prior, nb_simul=5e3, summary_stat_target=sum_stat_obs,
tolerance_tab=tolerance)
# Plot histogram
hist(ABC_Beaumont$param[,1])
# Plot density 2D
pdat <- as.data.frame(ABC_Beaumont$param)
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_density_2d()
tolerance=c(1,0.75,0.5,0.25,0.15)
# Run Sequencial Approximate Bayesian Computation
ABC_Beaumont <- ABC_sequential(method="Beaumont", model=toy_model,
prior=toy_prior, nb_simul=1e4, summary_stat_target=sum_stat_obs,
tolerance_tab=tolerance)
# Plot histogram
hist(ABC_Beaumont$param[,1])
# Plot density 2D
pdat <- as.data.frame(ABC_Beaumont$param)
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_density_2d()
hist(ABC_Beaumont$param[,2])
hist(ABC_Beaumont$param[,3])
hist(ABC_Beaumont$param[,4])
hist(ABC_Beaumont$param[,1])
pdat <- as.data.frame(ABC_Beaumont$param)
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_density_2d()
toy_model(c(x1,x2,x3,x4))
9200+1200
10400 + 3100
13500*3.9
52650 + 47000
9200+1300+3100
require(EasyABC)
require(ggplot2)
# Toy programm
# ======================================================================
#   COMPUTE PREDICTED VALUES: BLACK BOX
# ======================================================================
#     the numbers in the following equations are "hidden"
toy_model <- function(par){
val1 <- 1e-1*par[1]^4 +
2e-1*par[2]^3.0 +
7e-1*par[3]^2 +
4e-1*par[4];
val2 <- 3e-2*par[1]^4.0 +
5e-2*par[2]^3.0 +
9e-2*par[3]^2.0 +
1e-2*par[4];
val3 <- 7e-3*par[1]^4.0 +
1e-3*par[2]^3.0 +
4e-3*par[3]^2 +
2e-3*par[4];
val4 <- 2e-4*par[1]^4 +
5e-4*par[2]^3 +
8e-4*par[3]^2 +
8e-4*par[4]
val5 <- 9e-5*par[1]^4 +
6e-5*par[2]^3 +
3e-5*par[3]^2 +
1e-5*par[4]
#S1 <- mean(c(val1,val2,val3,val4))
#S2 <- sd(c(val1,val2,val3,val4))
return(c(log(val1),log(val2),log(val3),log(val4),log(val5)))
}
# Observed data
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
# Summary, just the data - no compression
sum_stat_obs <- obs_data
toy_prior <- list(c("unif",1e-1,1e3),c("unif",1e-1,1e3),
c("unif",1e-1,1e3),c("unif",1e-1,1e3))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=10
n_calib=10
tol_quant=0.2
ABC_Wegmann<-ABC_mcmc(method="Wegmann", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n, n_calibration=n_calib,
tolerance_quantile=tol_quant, use_seed=TRUE)
ABC_Wegmann
n=1e3
n_calib=1e2
tol_quant=0.1
ABC_Wegmann<-ABC_mcmc(method="Wegmann", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n, n_calibration=n_calib,
tolerance_quantile=tol_quant, use_seed=TRUE)
ABC_Wegmann<
hist(ABC_Wegmann $param[,1])
hist(ABC_Wegmann$param[,1])
ABC_Wegmann
ABC_Wegmann$param[,1]
n=1e3
n_calib=1e2
tol_quant=0.2
ABC_Wegmann <-ABC_mcmc(method="Wegmann", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n, n_calibration=n_calib,
tolerance_quantile=tol_quant, use_seed=TRUE)
hist(ABC_Wegmann$param[,1])
ABC_Wegmann
toy_model(c(x1,x2,x3,x4))
n=1e4
n_calib=1e3
tol_quant=0.2
ABC_Wegmann <-ABC_mcmc(method="Wegmann", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n, n_calibration=n_calib,
tolerance_quantile=tol_quant, use_seed=TRUE)
hist(ABC_Wegmann$param[,1])
ABC_Wegmann
sum_stat_obs
toy_model
n=1e4
tol_quant=0.2
ABC_Wegmann <- ABC_mcmc(method="Marjoram", model=toy_model, prior=toy_prior,
summary_stat_target=sum_stat_obs, n_rec=n,
tolerance_quantile=tol_quant, use_seed=TRUE)
ABC_Wegmann
n=1e4
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, use_seed=TRUE)
n=1e4
tol = 0.25
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
ABC_sim
hist(ABC_sim$param[,1])
n=1e4
tol = 0.2
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
n=1e4
tol = 0.1
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
dim(ABC_sim$param)
n=1e4
tol = 0.01
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
n=1e4
tol = 0.001
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
n=5e4
tol = 0.001
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
library(coda)
# assuming the data are 10 samples of a normal distribution
# with mean 5.3 and sd 2.7
data =  rnorm(10, mean =5.3, sd = 2.7)
# we want to use ABC to infer the parameters that were used.
# we sample from the same model and use mean and variance
# as summary statstitics. We return true for ABC acceptance when
# the difference to the data is smaller than a certain threshold
meandata <- mean(data)
standarddeviationdata <- sd(data)
ABC_acceptance <- function(par){
# prior to avoid negative standard deviation
if (par[2] <= 0) return(F)
# stochastic model generates a sample for given par
samples <- rnorm(10, mean = par[1], sd = par[2])
# comparison with the observed summary statistics
diffmean <- abs(mean(samples) - meandata)
diffsd <- abs(sd(samples) - standarddeviationdata)
if((diffmean < 0.1) & (diffsd < 0.2)) return(T) else return(F)
}
# we plug this in in a standard metropolis hastings MCMC,
# with the metropolis acceptance exchanged for the ABC acceptance
run_MCMC_ABC <- function(startvalue, iterations){
chain = array(dim = c(iterations+1,2))
chain[1,] = startvalue
for (i in 1:iterations){
# proposalfunction
proposal = rnorm(2,mean = chain[i,], sd= c(0.7,0.7))
if(ABC_acceptance(proposal)){
chain[i+1,] = proposal
}else{
chain[i+1,] = chain[i,]
}
}
return(mcmc(chain))
}
posterior <- run_MCMC_ABC(c(4,2.3),300000)
plot(posterior)
log(100)
toy_prior <- list(c("lognormal",log(100),log(100)),c("lognormal",log(100),log(100)),
c("lognormal",log(100),log(100)),log(100),log(100))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=5e4
tol = 0.001
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
toy_prior <- list(c("lognormal",log(100),log(100)),c("lognormal",log(100),log(100)),
c("lognormal",log(100),log(100)),c("lognormal",log(100),log(100)))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=5e4
tol = 0.001
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
n=5e4
tol = 0.01
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
ABC_sim$param
pdat <- as.data.frame(ABC_sim$param)
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_density_2d()
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_point()
n=1e5
tol = 0.1
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
range(rlnorm(log(100),log(100)))
range(rlnorm(log(100),log(100)))
range(rlnorm(1e5,log(100),log(100)))
range(rlnorm(1e5,log(100),log(10)))
range(rlnorm(1e5,log(10),log(10)))
range(rlnorm(1e5,log(10),log(1)))
range(rlnorm(1e5,log(10),log(10)))
range(rlnorm(1e5,log(10),log(5)))
range(rlnorm(1e5,log(10),log(2)))
range(rlnorm(1e5,log(10),log(3)))
range(rlnorm(1e5,log(10),log(2.5)))
range(rlnorm(1e5,log(1),log(2.5)))
toy_prior <- list(c("lognormal",log(2.5),log(2.5)),c("lognormal",log(2.5),log(2.5)),
c("lognormal",log(2.5),log(2.5)),c("lognormal",log(2.5),log(2.5)))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=1e5
tol = 0.1
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
pdat <- as.data.frame(ABC_sim$param)
ggplot(data = pdat,aes(x = V1,y = V2)) +
geom_point()
ggplot(data = pdat,aes(x = V1,y = V3)) +
geom_point()
hist(ABC_sim$param[,1])
mean(ABC_sim$param[,1])
median(ABC_sim$param[,1])
median(ABC_sim$param[10:,1])
median(ABC_sim$param[1:10,1])
ABC_sim
toy_model <- cmpfun(toy_model)
require(compiler)
toy_model <- cmpfun(toy_model)
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
# Summary, just the data - no compression
sum_stat_obs <- obs_data
toy_prior <- list(c("lognormal",log(2.5),log(2.5)),c("lognormal",log(2.5),log(2.5)),
c("lognormal",log(2.5),log(2.5)),c("lognormal",log(2.5),log(2.5)))
# Fraction of acceptable data, measured via Euclidian distance between simulation and obs_data
tolerance=c(1,0.75,0.5,0.25,0.15)
n=1e5
tol = 0.1
ABC_sim<-ABC_rejection(model=toy_model, prior=toy_prior, nb_simul=n, summary_stat_target=sum_stat_obs,tol=tol,
use_seed=TRUE)
hist(ABC_sim$param[,1])
hist(ABC_sim$param[,2])
hist(ABC_sim$param[,3])
hist(ABC_sim$param[,4])
#S1 <- mean(c(val1,val2,val3,val4))
#S2 <- sd(c(val1,val2,val3,val4))
return(c(log(val1),log(val2),log(val3),log(val4),log(val5)))
toy_model(c(x1,x2,x3,x4))
toy_model <- function(par){
val1 <- 1e-1*par[1]^4 +
2e-1*par[2]^3.0 +
7e-1*par[3]^2 +
4e-1*par[4];
val2 <- 3e-2*par[1]^4.0 +
5e-2*par[2]^3.0 +
9e-2*par[3]^2.0 +
1e-2*par[4];
val3 <- 7e-3*par[1]^4.0 +
1e-3*par[2]^3.0 +
4e-3*par[3]^2 +
2e-3*par[4];
val4 <- 2e-4*par[1]^4 +
5e-4*par[2]^3 +
8e-4*par[3]^2 +
8e-4*par[4]
val5 <- 9e-5*par[1]^4 +
6e-5*par[2]^3 +
3e-5*par[3]^2 +
1e-5*par[4]
#S1 <- mean(c(val1,val2,val3,val4))
#S2 <- sd(c(val1,val2,val3,val4))
return(c(val1,val2,val3,val4,val5))
}
toy_model <- cmpfun(toy_model)
# Observed data
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
obs_data
logit(34)
require(gtools)
logit(34)
inv.logit(34)
inv.logit(34)
inv.logit(90)
log(1003)
log(1004)
log(1004,10)
log(1003,10)
log(1003,100)
log(1004,100)
log(1004,1)
log(1003,1)
log(1003,2)
log(1004,2)
log(1004,1e4)
log(1003,1e4)
log(1003,0.2)
log(1004,0.2)
log(1004,1e-2)
log(1007,1e-2)
log(1010,1e-2)
log(32,1e-2)
log(12,1e-2)
log(500,1e-2)
log(500,10)
library(sparklyr)
options(sparklyr.java9 = TRUE)
sc <- spark_connect(master = "local")
iris_tbl <- sdf_copy_to(sc, iris, name = "iris_tbl")
media_petal <- iris_div %>%
group_by(Species) %>%
summarise(media = mean(Petal_Length))
sdf_num_partitions(iris_tbl)
iris_div <- sdf_repartition(iris_tbl, partitions = 3)
sdf_num_partitions(iris_div)
library(sparklyr)
spark_available_versions()
setwd("~/Documents/GitHub/ABC_Nuclear/GA_Fortran/examples")
zz <- file(zzfil, "syndat2.i3e")
zzfil <- tempfile("syndat2.i3e")
zz <- file(zzfil, "wb")
zz
readBin(zz)
readBin(zz,"raw")
zz <- file(zzfil, "rb")
readBin(zz,"raw")
readBin(zz,"numeric")
zz
tempfile("syndat2.i3e")
setwd("~/Documents/GitHub/ABC_Nuclear/GA_Fortran/examples")
tempfile("syndat2.i3e")
zzfil <- tempfile("syndat2.i3e")
read.fortran("syndat2.i3e")
require(EasyABC)
require(ggplot2)
# Toy programm
# ======================================================================
#   COMPUTE PREDICTED VALUES: BLACK BOX
# ======================================================================
#     the numbers in the following equations are "hidden"
toy_model <- function(par){
val1 <- 1e-1*par[1]^4 +
2e-1*par[2]^3.0 +
7e-1*par[3]^2 +
4e-1*par[4];
val2 <- 3e-2*par[1]^4.0 +
5e-2*par[2]^3.0 +
9e-2*par[3]^2.0 +
1e-2*par[4];
val3 <- 7e-3*par[1]^4.0 +
1e-3*par[2]^3.0 +
4e-3*par[3]^2 +
2e-3*par[4];
val4 <- 2e-4*par[1]^4 +
5e-4*par[2]^3 +
8e-4*par[3]^2 +
8e-4*par[4]
val5 <- 9e-5*par[1]^4 +
6e-5*par[2]^3 +
3e-5*par[3]^2 +
1e-5*par[4]
return(c(val1,val2,val3,val4,val5))
}
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
obs_data
require(GA)
# Toy programm
# ======================================================================
#   COMPUTE PREDICTED VALUES: BLACK BOX
# ======================================================================
#     the numbers in the following equations are "hidden"
toy_model <- function(par){
val1 <- 1e-1*par[1]^4 +
2e-1*par[2]^3.0 +
7e-1*par[3]^2 +
4e-1*par[4];
val2 <- 3e-2*par[1]^4.0 +
5e-2*par[2]^3.0 +
9e-2*par[3]^2.0 +
1e-2*par[4];
val3 <- 7e-3*par[1]^4.0 +
1e-3*par[2]^3.0 +
4e-3*par[3]^2 +
2e-3*par[4];
val4 <- 2e-4*par[1]^4 +
5e-4*par[2]^3 +
8e-4*par[3]^2 +
8e-4*par[4]
val5 <- 9e-5*par[1]^4 +
6e-5*par[2]^3 +
3e-5*par[3]^2 +
1e-5*par[4]
return(c(val1,val2,val3,val4,val5))
}
toy_model <- cmpfun(toy_model)
# Observed data
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
# Summary, just the data - no compression
sum_stat_obs <- obs_data
euc.dist <- function(x1, x2) sqrt(sum((x1 - x2)^2))
H.dist <- function(x1, x2) sqrt(sum((sqrt(x1) - sqrt(x2))^2))
R.dist <- function(x1, x2) sqrt(sum((log(x1) - log(x2))^2))
loss <- function(xx,yy,zz,kk){R.dist(toy_model(c(xx,yy,zz,kk)),obs_data)}
require(compile)
require(compiler)
require(GA)
# Toy programm
# ======================================================================
#   COMPUTE PREDICTED VALUES: BLACK BOX
# ======================================================================
#     the numbers in the following equations are "hidden"
toy_model <- function(par){
val1 <- 1e-1*par[1]^4 +
2e-1*par[2]^3.0 +
7e-1*par[3]^2 +
4e-1*par[4];
val2 <- 3e-2*par[1]^4.0 +
5e-2*par[2]^3.0 +
9e-2*par[3]^2.0 +
1e-2*par[4];
val3 <- 7e-3*par[1]^4.0 +
1e-3*par[2]^3.0 +
4e-3*par[3]^2 +
2e-3*par[4];
val4 <- 2e-4*par[1]^4 +
5e-4*par[2]^3 +
8e-4*par[3]^2 +
8e-4*par[4]
val5 <- 9e-5*par[1]^4 +
6e-5*par[2]^3 +
3e-5*par[3]^2 +
1e-5*par[4]
return(c(val1,val2,val3,val4,val5))
}
toy_model <- cmpfun(toy_model)
# Observed data
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
# Summary, just the data - no compression
sum_stat_obs <- obs_data
euc.dist <- function(x1, x2) sqrt(sum((x1 - x2)^2))
H.dist <- function(x1, x2) sqrt(sum((sqrt(x1) - sqrt(x2))^2))
R.dist <- function(x1, x2) sqrt(sum((log(x1) - log(x2))^2))
loss <- function(xx,yy,zz,kk){R.dist(toy_model(c(xx,yy,zz,kk)),obs_data)}
loss(c(34,12,500,7))
obs_data
loss(c(34,12,500,7),obs_data)
loss(34,12,500,7)
x1 = 34
x2 = 12
x3 = 456
x4 = 78
obs_data <- toy_model(c(x1,x2,x3,x4))
obs_data
5.9429998498671921E-002*500
1.3439999660477042E-002*500
0.99838997477854*500
0.53241998654993949*500
2^5
2^6
2^7
2^10
2^15
